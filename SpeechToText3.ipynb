{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2kexhg52zcgKqJT20uTn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleixbs/Python_bases/blob/main/SpeechToText3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIlH_EZN83tz",
        "outputId": "1638da22-8699-48a2-f4ae-05660d292bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-qoqwwcfo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-qoqwwcfo\n",
            "  Resolved https://github.com/openai/whisper.git to commit 1cea4357687b676b293cb5473e1ade25f5b1cef7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=801359 sha256=cfa7c1db3d1daf2b9f52ed844c43936d625890f3a796633f86b5d9409b9a2e03\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yhf1278_/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231106 tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sguIIFwd9BKO",
        "outputId": "5ca9bb7b-9b92-474e-f5d2-59e6fbf86c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,195 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,275 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,471 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,430 kB]\n",
            "Fetched 5,604 kB in 3s (1,759 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "8 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"audio3.mp4\" --model large-v3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK8mvHsBJFkz",
        "outputId": "de95fac1-1f95-4da8-9659-049aa93c2ae4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:08.320]  We will give you money. Fantastic. I will open up my AI calendar or my AI application\n",
            "[00:08.320 --> 00:16.120]  and I will simply tell it in very simple terms. There is an application due with the city of\n",
            "[00:16.120 --> 00:24.040]  Costa Brava in Portugal on the 27th of November. I would like you to remind me two weeks in advance\n",
            "[00:24.040 --> 00:30.700]  to send my proposal to my suppliers, ensure that the costs are all okay, and one week in advance\n",
            "[00:30.700 --> 00:39.200]  set a reminder to discuss with my team our proposal. And like magic, AI creates all of those\n",
            "[00:39.200 --> 00:47.900]  meeting requests, all of the calendar information, everything. And it's more like an\n",
            "[00:47.900 --> 00:53.680]  intelligent assistant. So if I can transfer that now maybe to a city application,\n",
            "[00:54.040 --> 00:59.820]  we are from Dublin. Our company will install a lot of the traffic signals and coordinated controls.\n",
            "[01:00.400 --> 01:06.500]  We believe in the future at some point, AI will be introduced in such a way that we can tell us\n",
            "[01:06.500 --> 01:12.520]  on Saturdays, our biggest football team, Dublin, play at the major stadium.\n",
            "[01:13.620 --> 01:18.300]  Here is a list of all the fixtures and all of the times the matches will take place.\n",
            "[01:18.900 --> 01:24.020]  We know we can coordinate with the traffic signals because it's an adaptive traffic control system.\n",
            "[01:24.040 --> 01:29.940]  I'm sure something you are all familiar with. It uses already a primitive form of AI to detect\n",
            "[01:29.940 --> 01:35.540]  traffic jams and change the light sequences. But what if we were able to use AI to tell us\n",
            "[01:35.540 --> 01:42.240]  for half an hour or an hour before the match, give all the routes towards the stadium,\n",
            "[01:42.580 --> 01:49.140]  extended green time access, and after the match, if the team win, change all the lights to blue.\n",
            "[01:49.260 --> 01:53.860]  No, I'm joking. We won't do that. But there are so many ways we could,\n",
            "[01:54.040 --> 02:00.660]  but we can't use it. Our company was started about 20 years ago. Traditionally was a maintenance\n",
            "[02:00.660 --> 02:05.620]  company, but we decided we wanted to be the best smart cities provider in Ireland.\n",
            "[02:06.020 --> 02:12.800]  So we established two sub companies within ours, which is for software development and traffic\n",
            "[02:12.800 --> 02:19.560]  installations. That means we have our own team on the ground, able to install lights, sensors,\n",
            "[02:19.560 --> 02:23.940]  any type of application, and our own software engineers,\n",
            "[02:24.040 --> 02:30.100]  to create all of the AI, the backend, and the machine learning that's required to provide the\n",
            "[02:30.100 --> 02:37.700]  best AI for Dublin. One of our most interesting pilot projects at the moment is done in\n",
            "[02:37.700 --> 02:43.580]  coordination with partners in the UK and around. And it's a huge problem in cities where you have\n",
            "[02:43.580 --> 02:50.580]  tram intersections with vehicles. A vehicle approaches a red light at high speed, and you\n",
            "[02:50.580 --> 02:53.900]  know instantly they are not going to be able to brake in time.\n",
            "[02:54.040 --> 02:58.840]  So we decided to make the red light. Nine times out of 10, the driver carries through the red light\n",
            "[02:58.840 --> 03:05.080]  and crashes straight into the tram. This can cause problems, obviously, for losing a public transport\n",
            "[03:05.080 --> 03:09.880]  vehicle for a certain amount of time while it's under repair, and then also the devastation it'll\n",
            "[03:09.880 --> 03:16.120]  cause the passengers and the cars. Our pilot program at the moment, instead of trying to stop\n",
            "[03:16.120 --> 03:23.980]  the car, it can read the speed of the approaching vehicle, make an assisted, educated decision that\n",
            "[03:23.980 --> 03:31.980]  this car will not stop in time for the red light, and instead it will stop the tram. It'll remove any\n",
            "[03:31.980 --> 03:38.060]  possibility for the public vehicle to cross the path of the speeding car. Now if we were to try\n",
            "[03:38.060 --> 03:43.340]  and introduce that based on people, it would be impossible. You would need one person per\n",
            "[03:43.340 --> 03:49.580]  intersection 24 hours a day to watch it. However, one AI system could watch over every single\n",
            "[03:49.580 --> 03:53.500]  junction that has a sensor that is monitoring all this data.\n",
            "[03:53.980 --> 03:59.980]  Which brings me to my real point. The ability for us to introduce AI and systems like this in\n",
            "[03:59.980 --> 04:05.520]  the future comes down to sensors. It comes down to the quality of the data that we are able to\n",
            "[04:05.520 --> 04:12.340]  collect in real time and bring on our cities. Really, we know AI won't really impact our lives.\n",
            "[04:12.540 --> 04:18.160]  We have a lovely saying in Ireland and Europe that a society grows stronger when its residents\n",
            "[04:18.160 --> 04:23.660]  plant trees whose shade they know they will never sit in. And this is what it's about. It is our\n",
            "[04:23.660 --> 04:23.960]  job to make sure that we have the data that we need to make sure that we have the data that we\n",
            "[04:23.960 --> 04:30.440]  need to put in the sensors so that the next generation can create life-changing AI applications.\n",
            "[04:31.480 --> 04:37.480]  We have made a small sensor for one of my most favourite projects that we have at the moment.\n",
            "[04:38.600 --> 04:42.760]  There's a lot of drownings in Ireland and it's unfortunate because we are surrounded\n",
            "[04:42.760 --> 04:48.440]  by so much water. And the lunch boys that are used to save someone who is drowning\n",
            "[04:48.440 --> 04:53.640]  regularly go missing, being stag dudes, being people using them. At the moment they are not\n",
            "[04:53.640 --> 04:59.320]  intelligent devices. A ring boy is lifted, it is thrown in the water to save someone and it is gone.\n",
            "[05:00.040 --> 05:06.600]  We developed a small sensor that sits at the bottom of the ring boy housing. It tells the\n",
            "[05:06.600 --> 05:11.800]  council when there is a life boy sensor present, but more importantly when there is not.\n",
            "[05:13.080 --> 05:17.640]  This then triggers the council to go out and replace the life boy.\n",
            "[05:17.640 --> 05:23.320]  They are not at a great cost, but what happens is it saves a life by ensuring there is\n",
            "[05:23.320 --> 05:29.640]  constantly a ring boy at the location a person needs there to be. But as we start to introduce\n",
            "[05:29.640 --> 05:35.400]  AI in the future, and again with our partners in the UK we are discovering this, if we develop that\n",
            "[05:35.400 --> 05:41.560]  sensor to a point where we know that it is being used or it can prove that the ring boy is being\n",
            "[05:41.560 --> 05:48.840]  used in an emergency situation and someone's life is in danger, that exact same trigger can be used\n",
            "[05:48.840 --> 05:53.240]  to send out drones to find where the person is in the water. It can be used to find where the person is in the water.\n",
            "[05:53.720 --> 06:00.280]  I give an exact GPS location. If the drone then confirms someone is drowning, it can trigger the\n",
            "[06:00.280 --> 06:06.920]  emergency response to the location to make sure that person is saved in time at the exact location\n",
            "[06:06.920 --> 06:14.360]  where they are in peril. It's a fantastic opportunity to utilize all of the technologies\n",
            "[06:14.360 --> 06:19.640]  that are available to us and we are very excited to keep developing this sensor and more.\n",
            "[06:20.280 --> 06:23.160]  If you are interested, we will be doing a demonstration\n",
            "[06:23.320 --> 06:31.720]  of this full system. Neil might have to tell me the exact location. It's the Smart Dublin stand\n",
            "[06:31.720 --> 06:37.560]  at three o'clock today. We have designed all of the software, all of the hardware,\n",
            "[06:37.560 --> 06:42.440]  and currently there are 600 of these sensors installed around Ireland at the moment.\n",
            "[06:49.720 --> 06:53.240]  I don't have a huge amount of time left, but I would like to thank\n",
            "[06:53.320 --> 06:59.640]  you for your participation and listening as cleanly as you have. As I said, Neil and I will\n",
            "[06:59.640 --> 07:04.600]  be on the Smart Dublin stand for most of the day. We can take you through all of our other\n",
            "[07:05.160 --> 07:11.240]  applications of AI that we are using, but we firmly believe that this is the future\n",
            "[07:11.240 --> 07:18.120]  of smart cities and the sooner we can start to see it as an assisted intelligence instead\n",
            "[07:18.120 --> 07:22.680]  of an artificial intelligence, the better all of our cities and public spaces will be.\n",
            "[07:23.320 --> 07:25.560]  Thank you for your time. Welcome any questions.\n",
            "[07:29.320 --> 07:30.760]  Give it up to Gengover, everyone.\n",
            "[07:32.520 --> 07:38.040]  All right. Well, thank you very much for this very interesting presentation and how we are putting\n",
            "[07:38.040 --> 07:45.640]  safety of our users first. Now, we still have maybe just about five minutes in case anybody\n",
            "[07:45.640 --> 07:51.880]  would want to ask a question. We have the microphone here in the front, so don't be shy.\n",
            "[07:51.880 --> 07:53.000]  Come over and ask a question.\n",
            "[07:54.200 --> 07:57.320]  It's always hard to speak the first. Nobody wants to speak at the start.\n",
            "[07:57.320 --> 07:58.520]  Who wants to break the ice?\n",
            "[08:01.320 --> 08:05.480]  Anyone? Then Ken, in the meantime, because we discussed that\n",
            "[08:06.360 --> 08:12.440]  before, the other day in our call. How much do you use AI in your day-to-day life? How many\n",
            "[08:12.440 --> 08:13.320]  times do you use it per day?\n",
            "[08:14.920 --> 08:20.280]  No, I do. I use it a lot. I gave the example at the start of using it to control my calendar,\n",
            "[08:20.280 --> 08:23.320]  using it as an assistant to set reminders. I'm an assistant to a standard system, which I'm an\n",
            "[08:23.320 --> 08:28.920]  extremely forgetful i'm sure some of you are fantastic at making notes at conferences and\n",
            "[08:28.920 --> 08:35.100]  putting them into your calendar and all that but it is almost impossible for me i tend to\n",
            "[08:35.100 --> 08:40.260]  months after the event find a scrambled up piece of paper at the bottom of my bag and go oh they\n",
            "[08:40.260 --> 08:45.280]  were the notes i took on the day whereas now with ai technologies and it's as simple as the\n",
            "[08:45.280 --> 08:50.640]  microsoft applications yesterday microsoft were on stage with open ai talking about their\n",
            "[08:50.640 --> 08:56.300]  partnership they had their developer conference and most of the applications for ai are already\n",
            "[08:56.300 --> 09:02.360]  in your computer it's not something you have to download or sign up to chat gbt for turbo\n",
            "[09:02.360 --> 09:09.740]  even microsoft to do has so many applications where you can just speak to it in a conversational\n",
            "[09:09.740 --> 09:16.260]  tone and suddenly before you know it all of these triggers are set that can assist your day for\n",
            "[09:16.260 --> 09:20.380]  reminders for uh yes yes setting setting uh\n",
            "[09:20.640 --> 09:26.220]  tasks to do that you're most likely to forget so as a forgetful person that i am i should be\n",
            "[09:26.220 --> 09:30.700]  anyone wanting to ask a question to uh to ken\n",
            "[09:30.700 --> 09:36.680]  all right then i think people have noted down uh your 3 p.m\n",
            "[09:36.680 --> 09:39.780]  demonstrations so make sure to check it at the smart\n",
            "[09:39.780 --> 09:43.340]  stand excellent thank you guys thank you so much\n",
            "[09:43.340 --> 09:50.340]  all right so now we are moving to the\n",
            "[09:50.640 --> 09:58.000]  second one of our solution talks of this session this one coming from a little bit closer to to our\n",
            "[09:58.000 --> 10:04.880]  home these days and i'm delighted to introduce actually one of the partners of eit uh tomorrow\n",
            "[10:04.880 --> 10:10.640]  mobility event uh i'm talking about the planification manager at moventis nuria\n",
            "[10:10.640 --> 10:16.640]  gluminas\n",
            "[10:16.640 --> 10:18.640]  welcome\n",
            "[10:18.640 --> 10:20.640]  thank you\n",
            "[10:20.640 --> 10:28.640]  uh good morning uh first of all thank you very much for inviting us to this session\n",
            "[10:29.440 --> 10:36.640]  we're very proud to be here for those who don't know moventis moventis is moventia's business unit\n",
            "[10:36.640 --> 10:44.640]  dedicated to collective mobility this division brings together all the companies of the group\n",
            "[10:44.640 --> 10:50.480]  that develop their business through the transfer of passengers in buses in coaches\n",
            "[10:50.640 --> 10:59.440]  streetcars or other mortals transports like public rental bicycles or carpooling\n",
            "[10:59.440 --> 11:13.440]  moventis is focused on providing innovative solutions that contribute to get sustainable connected and safe mobility for all users\n",
            "[11:13.440 --> 11:20.320]  in 2017 moventis started to collaborate with the technological platform shuttle\n",
            "[11:20.320 --> 11:20.340]  in 2017 moventis started to collaborate with the technological platform shuttle\n",
            "[11:20.640 --> 11:24.000]  to implement a transport on demand line in the city of san cuvada\n",
            "[11:24.000 --> 11:25.360]  to implement a transport on demand line in the city of san cuvada\n",
            "[11:25.360 --> 11:29.440]  nowadays we are operating three transport and demand lines in this city\n",
            "[11:29.440 --> 11:36.720]  with shuttle's solution for the user this solution consists in an application\n",
            "[11:36.720 --> 11:44.080]  the user when wants to take a trip he makes the request through the application and it tells him\n",
            "[11:44.080 --> 11:50.480]  when the bus is going to pick him up i'll try to explain very briefly how artificial\n",
            "[11:50.480 --> 11:50.560]  i'll try to explain very briefly how artificial\n",
            "[11:50.560 --> 11:53.040]  intelligence has improved this platform\n",
            "[11:56.320 --> 11:59.920]  to create artificial intelligence we need algorithms and data\n",
            "[12:01.120 --> 12:08.000]  on the transport on demand case the algorithm must solve a problem called the dial or right problem\n",
            "[12:08.560 --> 12:15.040]  in this problem we have n requests k vehicles and some constraints like the capacity of the\n",
            "[12:15.040 --> 12:20.320]  vehicles or the hours of operation and the goal is to optimize the service\n",
            "[12:20.960 --> 12:24.160]  i i i don't think you can hope to get the correct answer\n",
            "[12:24.160 --> 12:26.160]  i i don't think you can hope to get the correct answer\n",
            "[12:26.160 --> 12:28.160]  it can be a little bit subjective depending on the operation\n",
            "[12:28.640 --> 12:32.080]  what does it mean optimizing the service well it can be a little bit subjective\n",
            "[12:32.080 --> 12:35.600]  depending on the operation to solve the problem we will use a realistic algorithm\n",
            "[12:36.000 --> 12:42.720]  and with these algorithms maybe we won't get an exact solution but we can get a\n",
            "[12:42.720 --> 12:49.120]  solution solution that it's pretty close to the exact one and the computational time is less than\n",
            "[12:49.120 --> 12:58.480]  algorithm that is an algorithm from 1959 if we have a lot of requests at the same\n",
            "[12:58.480 --> 13:04.220]  time with this algorithm that is very efficient we could take too long too\n",
            "[13:04.220 --> 13:09.980]  long to solve the problem that's why shuttle technicians decided to explore\n",
            "[13:09.980 --> 13:14.980]  other routing algorithms that would fit in the problem to compare the different\n",
            "[13:14.980 --> 13:19.580]  algorithms they studied the computational time required to solve the\n",
            "[13:19.580 --> 13:27.940]  problem and the efficiency respect the extra algorithm today the platform works with\n",
            "[13:27.940 --> 13:33.160]  four algorithms working in parallel and a timeout if the best algorithm gets a\n",
            "[13:33.160 --> 13:39.200]  solution before timeout the application will show these results but if the best\n",
            "[13:39.200 --> 13:44.320]  algorithm cannot get a solution before timeout then it will pass to the second\n",
            "[13:44.980 --> 13:51.640]  and so on to the fourth. another AI technique applied in shuttle is\n",
            "[13:51.660 --> 13:56.720]  clustering. when we talk about clustering we thought about grouping data in\n",
            "[13:56.720 --> 14:02.960]  clusters or groups trying to find characteristics that we wouldn't find\n",
            "[14:02.960 --> 14:10.040]  with our techniques. for example, shuttle has historical data of real trips where\n",
            "[14:10.040 --> 14:14.520]  they asked the users to score the satisfaction of the trip\n",
            "[14:14.980 --> 14:22.660]  The users have to score the global satisfaction, the waiting time satisfaction and the satisfaction\n",
            "[14:22.660 --> 14:24.660]  respect the delay.\n",
            "[14:24.660 --> 14:29.760]  When we say delay we mean the difference between the real drop of time and the expected drop\n",
            "[14:29.760 --> 14:30.760]  of time.\n",
            "[14:30.760 --> 14:37.380]  During this clustering we can see if each point is a trip, that there are three main\n",
            "[14:37.380 --> 14:39.260]  groups of trips.\n",
            "[14:39.260 --> 14:44.580]  The blue ones would be those where the user is more satisfied.\n",
            "[14:44.580 --> 14:51.780]  With the clustering we can find trip profiles and user profiles and this will help to personalize\n",
            "[14:51.780 --> 14:55.160]  the algorithm for each operation.\n",
            "[14:55.160 --> 14:59.560]  Because it's not the same taking the bus on a Monday when you have to go to work and you\n",
            "[14:59.560 --> 15:06.820]  need to be there at some hour or taking the bus on a Saturday afternoon when everything\n",
            "[15:06.820 --> 15:08.220]  is more relaxed.\n",
            "[15:08.220 --> 15:09.220]  So, that's it.\n",
            "[15:09.220 --> 15:15.360]  Another artificial intelligence technique applied is machine learning.\n",
            "[15:15.360 --> 15:21.120]  With all the historical data they train the machine so the machine can do predictions\n",
            "[15:21.120 --> 15:22.900]  on the demand.\n",
            "[15:22.900 --> 15:27.540]  With these predictions then the algorithm recalculates the time and gives a new expected\n",
            "[15:27.540 --> 15:31.360]  time that is more accurate than the first one.\n",
            "[15:31.360 --> 15:38.540]  So, if we come back to the day to day of Moventis we can see that the demand has been increasing.\n",
            "[15:38.540 --> 15:48.220]  So, we can say that artificial intelligence is now a reality in the transport sector.\n",
            "[15:48.220 --> 15:56.200]  With artificial intelligence we can provide a better service so we have happier users.\n",
            "[15:56.200 --> 16:02.860]  Thank you very much.\n",
            "[16:02.860 --> 16:06.320]  Thank you very much Nuria for this interesting presentation and this interesting example\n",
            "[16:06.320 --> 16:06.680]  actually pretty close from over here.\n",
            "[16:08.540 --> 16:14.760]  We still have a little bit of time for some questions.\n",
            "[16:14.760 --> 16:18.300]  If anybody would like to ask a question about Nuria's presentation?\n",
            "[16:18.300 --> 16:19.300]  Let me see.\n",
            "[16:19.300 --> 16:20.300]  Over here.\n",
            "[16:20.300 --> 16:26.720]  There is a microphone over there if you want to get this.\n",
            "[16:26.720 --> 16:28.720]  Thanks for breaking the ice.\n",
            "[16:28.720 --> 16:29.720]  Hi.\n",
            "[16:29.720 --> 16:30.720]  Hi.\n",
            "[16:30.720 --> 16:31.720]  I am from the Netherlands.\n",
            "[16:31.720 --> 16:33.220]  I am not really familiar with the on demand services like you are explaining.\n",
            "[16:33.220 --> 16:34.220]  So, how does that work if there are no passengers, there are no buses?\n",
            "[16:34.220 --> 16:35.220]  So, I have a question.\n",
            "[16:35.220 --> 16:36.220]  I am from the Netherlands.\n",
            "[16:36.220 --> 16:37.220]  I am not familiar with the on demand services like you are explaining.\n",
            "[16:37.220 --> 16:38.220]  So, how does that work?\n",
            "[16:38.540 --> 16:39.540]  So, there are no passengers.\n",
            "[16:39.540 --> 16:40.540]  Just on the practical side.\n",
            "[16:40.540 --> 16:45.540]  If there are no passengers the bus is stopped and it is not running.\n",
            "[16:45.540 --> 16:46.540]  That's all.\n",
            "[16:46.540 --> 16:51.540]  Is there a minimum of people that have to make a demand?\n",
            "[16:51.540 --> 16:56.540]  The service is planned so the driver is prepared to do the service.\n",
            "[16:56.540 --> 17:03.300]  We have the driver, we have the bus and if there is no passenger the driver is like this.\n",
            "[17:03.300 --> 17:04.300]  Okay, perfect.\n",
            "[17:04.300 --> 17:05.300]  Thank you.\n",
            "[17:05.300 --> 17:07.300]  Thank you very much for the question.\n",
            "[17:07.300 --> 17:08.300]  Thanks for another question.\n",
            "[17:08.300 --> 17:15.300]  There is another one over here.\n",
            "[17:15.300 --> 17:16.300]  Hi everyone.\n",
            "[17:16.300 --> 17:19.300]  Thank you very much for the presentation.\n",
            "[17:19.300 --> 17:23.300]  So, my question is about when does it make sense to implement demand transport and what\n",
            "[17:23.300 --> 17:30.300]  kind of situation, what kind of values within the city or the rural realm and also how to\n",
            "[17:30.300 --> 17:33.300]  deploy a system from the beginning.\n",
            "[17:33.300 --> 17:34.300]  Thank you.\n",
            "[17:34.300 --> 17:35.300]  Well, usually we implement this kind of lines.\n",
            "[17:35.300 --> 17:36.300]  So, what do we do?\n",
            "[17:36.300 --> 17:44.100]  kind of lines in cities places with a low density where having a regular line\n",
            "[17:44.100 --> 17:53.940]  would be not efficient if I'm having passengers that in peak hour we know\n",
            "[17:53.940 --> 17:59.540]  that we can give the service with the demand bus\n",
            "[17:59.540 --> 18:08.760]  thank you any final question please I can come on to the microphone thank you\n",
            "[18:11.120 --> 18:14.980]  in the idea is that and if anybody would want to ask questions to stand on the\n",
            "[18:14.980 --> 18:17.140]  line\n",
            "[18:21.400 --> 18:26.920]  how much did you learn from other cities who tried similar approaches I know\n",
            "[18:26.920 --> 18:29.460]  Helsinki has something like this like maybe ten years ago\n",
            "[18:29.540 --> 18:34.160]  so how is this different or maybe just time you've changed so it's a better\n",
            "[18:34.160 --> 18:42.260]  situation now than it was before well probably all these platforms are yet\n",
            "[18:42.260 --> 18:47.660]  they were pretty similar way some years ago maybe 50 years ago we started trying\n",
            "[18:47.660 --> 18:53.780]  this kind of services with the typical series that the user had to call the day\n",
            "[18:53.780 --> 18:59.520]  before and had to say hey tomorrow I need the service now with all the\n",
            "[18:59.520 --> 19:08.340]  technology we can do it through this application and probably all the\n",
            "[19:08.340 --> 19:14.700]  people that is dedicated to study of this kind of algorithms are in contact with one\n",
            "[19:14.700 --> 19:21.640]  with other ones and they learn from one from one operation from from others\n",
            "[19:23.680 --> 19:27.680]  maybe since we still have one minute let's do it\n",
            "[19:27.680 --> 19:29.360]  I do have a final question\n",
            "[19:29.520 --> 19:31.880]  of the respect of the users because\n",
            "[19:31.880 --> 19:37.660]  anytime we encounter a new application a new app or new technology it's not always\n",
            "[19:37.660 --> 19:42.600]  easy to get people to use it yes how difficult or how easy maybe was it\n",
            "[19:42.600 --> 19:48.880]  for you for the users in Sankoogat to adopt the the usage of the shuttle\n",
            "[19:48.880 --> 19:56.260]  well we have the application and then there is a form for people that is not used to this kind of technology\n",
            "[19:56.260 --> 19:59.220]  at the beginning the percentage of people that was\n",
            "[19:59.520 --> 20:04.520]  requesting the service for the phone was around maybe 50%.\n",
            "[20:04.520 --> 20:09.520]  Nowadays, the percentage is around 8%.\n",
            "[20:09.520 --> 20:13.520]  So, every time we have more people using the application,\n",
            "[20:13.520 --> 20:16.520]  less people have to use it.\n",
            "[20:16.520 --> 20:22.520]  Very good. And then there's also people of certain ages\n",
            "[20:22.520 --> 20:25.520]  that don't necessarily understand the phone, but they can still call.\n",
            "[20:25.520 --> 20:28.520]  They can call, they can. Really interesting.\n",
            "[20:28.520 --> 20:31.520]  All right, Nuria, so thank you very much for being with us for the presentation\n",
            "[20:31.520 --> 20:34.520]  and for taking the time to answer our questions.\n",
            "[20:34.520 --> 20:36.520]  Thank you very much.\n",
            "[20:39.520 --> 20:43.520]  All right, so we saw two case studies, two examples,\n",
            "[20:43.520 --> 20:49.520]  on how different AI applications are being used in Dublin and in Barcelona.\n",
            "[20:49.520 --> 20:53.520]  Now it's time to discuss in more detail the innovations,\n",
            "[20:53.520 --> 20:57.520]  the implications, the policies needed, everything around\n",
            "[20:57.520 --> 20:58.520]  what do we do?\n",
            "[20:58.520 --> 21:02.520]  In terms of data and all other matters.\n",
            "[21:02.520 --> 21:07.520]  So stay tuned because in just a minute we're starting the panel discussion.\n",
            "[21:28.520 --> 21:31.520]  All right, and welcome back, everyone.\n",
            "[21:31.520 --> 21:34.520]  That was a short, that was a very short break.\n",
            "[21:34.520 --> 21:38.520]  Well, as mentioned, we're starting the second part of our session,\n",
            "[21:38.520 --> 21:43.520]  so welcome everyone who is joining us just now.\n",
            "[21:43.520 --> 21:47.520]  After these two examples that we've been seeing on the case of\n",
            "[21:47.520 --> 21:51.520]  different artificial intelligence usage in urban mobility,\n",
            "[21:51.520 --> 21:57.520]  we're going to be diving deep on many topics, I think, from the perspective of\n",
            "[21:57.520 --> 22:06.520]  mobility providers to public entities to how cities can better cooperate with innovators.\n",
            "[22:06.520 --> 22:10.520]  So I would like to invite my panelists to join me here on stage.\n",
            "[22:10.520 --> 22:12.520]  I will introduce them in just a second.\n",
            "[22:27.520 --> 22:37.520]  I guess you can stay here.\n",
            "[22:37.520 --> 22:38.520]  Excellent.\n",
            "[22:38.520 --> 22:43.520]  So thank you very much to all of you for having joined this panel discussion.\n",
            "[22:43.520 --> 22:50.520]  I think we have a great speaker lineup and I'm very excited to discuss in more detail\n",
            "[22:50.520 --> 22:52.520]  such a fascinating topic.\n",
            "[22:52.520 --> 22:56.520]  I mean, we have a cool room just in front of us.\n",
            "[22:56.520 --> 23:00.520]  Just next to me, I'm delighted to introduce the mobility innovation expert\n",
            "[23:00.520 --> 23:05.520]  coming all the way from London and the former head of innovation at Transport for London,\n",
            "[23:05.520 --> 23:06.520]  Mr. Rikesh Shah.\n",
            "[23:06.520 --> 23:09.520]  Thanks for being with us.\n",
            "[23:09.520 --> 23:12.520]  Also with us is Anne Irefusta Barrena.\n",
            "[23:12.520 --> 23:16.520]  She's a technology director for industry and mobility at Technalia.\n",
            "[23:16.520 --> 23:18.520]  Thank you for being with us.\n",
            "[23:18.520 --> 23:23.520]  On my other side, I'm delighted to introduce from the Frank Hofer Institute for Industrial Engineering,\n",
            "[23:23.520 --> 23:24.520]  Marco Amorim.\n",
            "[23:24.520 --> 23:25.520]  Hi.\n",
            "[23:25.520 --> 23:26.520]  Hi.\n",
            "[23:26.520 --> 23:32.520]  So with us is the CTO and Assistant City Manager at the City of Pinched Tree Corners in the\n",
            "[23:32.520 --> 23:34.520]  U.S., Brandon Branham.\n",
            "[23:34.520 --> 23:39.520]  So I would like to start with you, Rikesh Shah.\n",
            "[23:39.520 --> 23:46.520]  When we talk about such a global metropolis, such a global city like London, what are the\n",
            "[23:46.520 --> 23:51.520]  opportunities that AEI has brought for its mobility network?\n",
            "[23:51.520 --> 23:53.520]  What can you tell us about that?\n",
            "[23:53.520 --> 23:54.520]  Thank you.\n",
            "[23:54.520 --> 23:55.520]  Can you hear me okay?\n",
            "[23:55.520 --> 23:56.520]  Yeah.\n",
            "[23:56.520 --> 23:57.520]  So I think the role of AEI is a new thing.\n",
            "[23:57.520 --> 23:58.520]  You know, AEI has been around a long time, since the 1950s.\n",
            "[23:58.520 --> 23:59.520]  And I just go to what Ken said earlier, it's really relevant, is when I wake up in the\n",
            "[23:59.520 --> 24:00.520]  morning, I might check my diary or I might then check the news, which is based on what\n",
            "[24:00.520 --> 24:01.520]  I want to read.\n",
            "[24:01.520 --> 24:02.520]  I might then do my journey planning.\n",
            "[24:02.520 --> 24:03.520]  So if I do my journey planning, people like TFL are releasing the data.\n",
            "[24:03.520 --> 24:04.520]  We release hundreds of data sets.\n",
            "[24:04.520 --> 24:05.520]  There are over 700 apps in London that are powered by TFL data.\n",
            "[24:05.520 --> 24:06.520]  And that's based on the data that we have.\n",
            "[24:06.520 --> 24:07.520]  So if I do my journey planning, people like TFL are releasing the data.\n",
            "[24:07.520 --> 24:08.520]  We release hundreds of data sets.\n",
            "[24:08.520 --> 24:09.520]  There are over 700 apps in London that are powered by TFL data.\n",
            "[24:09.520 --> 24:10.520]  And that's based on the data that we have.\n",
            "[24:10.520 --> 24:27.080]  And that's based on my preference, 42% of Londoners use an app that's relevant to them.\n",
            "[24:27.080 --> 24:32.640]  So that's a form of AI.\n",
            "[24:32.640 --> 24:35.520]  Then if I get onto the road, the traffic's optimized.\n",
            "[24:35.520 --> 24:39.080]  The traffic's optimized based on the traffic lights and how you work.\n",
            "[24:39.080 --> 24:40.080]  The city wants to control the traffic.\n",
            "[24:40.080 --> 24:40.500]  So what can I do?\n",
            "[24:40.520 --> 24:44.200]  Then there might be a road safety element.\n",
            "[24:44.200 --> 24:49.080]  So it could be a case of what data is coming out of the cars, what data is coming out of\n",
            "[24:49.080 --> 24:50.080]  the vehicles.\n",
            "[24:50.080 --> 24:53.080]  So actually the opportunities have been there for a long time.\n",
            "[24:53.080 --> 24:55.860]  And the opportunities will continue to be there going forward.\n",
            "[24:55.860 --> 24:58.780]  I think where we need to be clear is what are the problems that we're trying to solve\n",
            "[24:58.780 --> 25:01.960]  for our cities in the short, medium and long term.\n",
            "[25:01.960 --> 25:02.960]  And then what outcomes do you want?\n",
            "[25:02.960 --> 25:06.220]  And if we don't get that right, it just becomes a technology thing.\n",
            "[25:06.220 --> 25:10.240]  So we've got to contextualise everything really well, which I'm sure we're doing well today.\n",
            "[25:10.240 --> 25:11.240]  Contextualising, indeed.\n",
            "[25:11.240 --> 25:17.480]  And I think already we've got some hints on really how do we put the needs of our passengers,\n",
            "[25:17.480 --> 25:18.480]  of our users first.\n",
            "[25:18.480 --> 25:22.480]  And we're going to be getting back to it very shortly, indeed.\n",
            "[25:22.480 --> 25:26.100]  Then I'd like to turn to Brandon Brown.\n",
            "[25:26.100 --> 25:30.660]  So the city of page three corners, it would be great if first of all, you can also put\n",
            "[25:30.660 --> 25:32.740]  us on the map.\n",
            "[25:32.740 --> 25:37.300]  I think that no one better to introduce us than you.\n",
            "[25:37.300 --> 25:40.220]  And how is it implementing AI in a smart city?\n",
            "[25:40.220 --> 25:44.460]  Thank you for those in the room.\n",
            "[25:44.460 --> 25:49.120]  We are just north of Atlanta, so 20 minutes from downtown Atlanta.\n",
            "[25:49.120 --> 25:52.860]  We like to say Atlanta is a suburb of Peachtree Corners.\n",
            "[25:52.860 --> 25:57.720]  But what we're seeing, obviously, in the metropolitan area, and Kim hit it on earlier, is traffic\n",
            "[25:57.720 --> 25:58.720]  is a major concern.\n",
            "[25:58.720 --> 26:01.940]  As we all know, the US is very car centric.\n",
            "[26:01.940 --> 26:05.680]  So how do we take use of the infrastructure to start to improve that?\n",
            "[26:05.680 --> 26:09.460]  We have a corridor that cuts through the heart of our city that carries 60,000 cars a day.\n",
            "[26:09.460 --> 26:13.700]  Right through the middle of our downtown area.\n",
            "[26:13.700 --> 26:18.140]  And so we're starting to do those things in traffic using the sensor sets that are on\n",
            "[26:18.140 --> 26:19.140]  there.\n",
            "[26:19.140 --> 26:22.140]  But then we decided to introduce an autonomous shuttle.\n",
            "[26:22.140 --> 26:25.300]  So how does that start to interact with the infrastructure?\n",
            "[26:25.300 --> 26:31.600]  So we use the AI sets that are on the sensor stack in the shuttle to communicate with our\n",
            "[26:31.600 --> 26:32.600]  infrastructure.\n",
            "[26:32.600 --> 26:37.700]  So we start to do preemption of traffic signals through that, and trying to find ways, because\n",
            "[26:37.700 --> 26:38.700]  in the US, public transportation is a major concern.\n",
            "[26:38.700 --> 26:47.380]  So how do we start to make it a viable option using AI in transportation and transportation\n",
            "[26:47.380 --> 26:48.380]  infrastructure?\n",
            "[26:48.380 --> 26:55.380]  Because I think how we're going to get there and the stuff that we're starting to do in\n",
            "[26:55.380 --> 26:56.380]  district orders.\n",
            "[26:56.380 --> 26:57.380]  So thank you.\n",
            "[26:57.380 --> 26:58.380]  Thank you very much.\n",
            "[26:58.380 --> 26:59.380]  I think, yeah, it's very, very interesting to see how different cities are implementing\n",
            "[26:59.380 --> 27:00.380]  solutions from all over the world.\n",
            "[27:00.380 --> 27:01.380]  So I would like then to turn to our next speaker, Anaida Fustavarena of Tecnalia.\n",
            "[27:01.380 --> 27:02.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:02.380 --> 27:03.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:03.380 --> 27:04.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:04.380 --> 27:05.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:05.380 --> 27:06.380]  Anaida Fustavarena.\n",
            "[27:06.380 --> 27:07.380]  Anaida Fustavarena.\n",
            "[27:07.380 --> 27:08.380]  Anaida Fustavarena.\n",
            "[27:08.380 --> 27:09.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:09.380 --> 27:10.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:10.380 --> 27:11.380]  Anaida Fustavarena of Tecnalia.\n",
            "[27:11.380 --> 27:19.120]  What are the AI solutions that you are looking into specifically and what do you think is\n",
            "[27:19.120 --> 27:20.740]  needed to scale them up?\n",
            "[27:20.740 --> 27:23.740]  Okay, thank you, Ana.\n",
            "[27:23.740 --> 27:27.500]  Thank you to Tomorrow Mobility for inviting us, Tecnalia, to reply to this relevant question\n",
            "[27:27.500 --> 27:30.840]  about upscaling solutions, AI solutions.\n",
            "[27:30.840 --> 27:38.100]  So we have seen two nice solutions in the first part of this session.\n",
            "[27:38.100 --> 27:47.620]  Well, I would first of all say that most AI developments remain as a proof of concept.\n",
            "[27:48.520 --> 27:51.760]  So it's difficult, they are tested offline,\n",
            "[27:51.760 --> 27:59.760]  and it's difficult to really have the whole life cycle for widespread errors\n",
            "[28:00.400 --> 28:04.880]  and for giving the necessary time to this whole life cycle\n",
            "[28:04.880 --> 28:09.620]  to really find or validate the solution.\n",
            "[28:10.020 --> 28:16.220]  So this life cycle needs to take into account ML, machine learning operations,\n",
            "[28:16.460 --> 28:18.740]  data operations, AI operations.\n",
            "[28:18.740 --> 28:23.160]  And so I think this is one of the most relevant aspects\n",
            "[28:23.160 --> 28:27.480]  that we need to take into account for upscaling AI solutions.\n",
            "[28:27.920 --> 28:34.860]  Then I think AI-based solutions must incorporate adequate management of the expectations\n",
            "[28:34.860 --> 28:34.880]  and the expectations of the AI.\n",
            "[28:34.880 --> 28:38.780]  So the steps must be incremental,\n",
            "[28:39.700 --> 28:47.120]  and an incremental roadmap, realistic, taking into account quick wins, must be applied.\n",
            "[28:48.000 --> 28:51.260]  Then access to skills, access to talent,\n",
            "[28:51.560 --> 28:57.160]  this is also something we need and it's relevant for the upscaling.\n",
            "[28:58.020 --> 29:02.580]  And the acceptance by professionals of a human-centered AI approach,\n",
            "[29:02.580 --> 29:04.480]  perhaps in the two nice solutions,\n",
            "[29:04.660 --> 29:04.860]  and one of the most important ones,\n",
            "[29:04.860 --> 29:09.300]  and at least that this is relevant and needs to take into account.\n",
            "[29:09.980 --> 29:14.160]  And then another clear aspect is the regulatory framework.\n",
            "[29:15.020 --> 29:19.060]  So this can be agreed at a global level.\n",
            "[29:20.340 --> 29:25.960]  These steps are taken to regulate the AI.\n",
            "[29:26.260 --> 29:30.440]  We have this sandbox on AI, the AI Act,\n",
            "[29:30.960 --> 29:33.940]  that will be defined and validated in two years' time.\n",
            "[29:33.940 --> 29:34.640]  So all of these steps are taken to regulate the AI.\n",
            "[29:34.640 --> 29:45.620]  So all this is needed, and I think these are, I would say, the most relevant aspects we need to take into account for the upscaling of AI solutions to the market.\n",
            "[29:46.520 --> 29:52.660]  Very interesting. You've put some important ingredients on the table. I've noted down the expectations, being realistic.\n",
            "[29:53.220 --> 29:57.120]  The access to skills and talent, when you were saying that, the room next to us was applauding.\n",
            "[29:57.320 --> 30:01.120]  So I think it probably resonated even in the other side of the room as well.\n",
            "[30:01.120 --> 30:07.460]  So these are all, I think, important questions that we will also take in the panel, indeed.\n",
            "[30:07.960 --> 30:15.160]  And then, last but not least, before I move, I open the debate, I would like to turn to Marco to tell us,\n",
            "[30:15.780 --> 30:21.660]  because you've been doing extensive research on how users perceive artificial intelligence.\n",
            "[30:21.920 --> 30:29.040]  So how would you assess it generally? The average user would perceive solutions of AI mobility.\n",
            "[30:29.040 --> 30:30.500]  What are their preferences?\n",
            "[30:31.120 --> 30:35.600]  What are the, I don't know, uncertainties or fears? What can you tell us?\n",
            "[30:35.600 --> 30:44.500]  Yeah, that's a good question, and quite a complex one, but so I will just point three main points that I think are quite interesting ones.\n",
            "[30:44.500 --> 30:45.880]  So the first one is habits.\n",
            "[30:45.880 --> 30:53.220]  So as humans, we are people of habits, so we like to stick to what we know, the way we do things.\n",
            "[30:53.220 --> 31:00.960]  So usually we don't like to go out of our comfort zone, and we have some studies, for example, that shows that cities,\n",
            "[31:00.960 --> 31:06.600]  where there have been pilots for automated vehicles, shuttles, or normal vehicles,\n",
            "[31:07.080 --> 31:12.340]  people usually are more willing to accept those technologies in the future.\n",
            "[31:12.800 --> 31:16.020]  So this is something that can prove this fact of the habits.\n",
            "[31:16.500 --> 31:18.200]  The next part is trust.\n",
            "[31:18.740 --> 31:23.920]  So we need to trust these new technologies or new service.\n",
            "[31:25.500 --> 31:29.300]  And for that, there is always a question.\n",
            "[31:30.000 --> 31:30.920]  Is this service reliable?\n",
            "[31:30.960 --> 31:32.220]  I mean, I never used it.\n",
            "[31:32.240 --> 31:33.000]  Will it work?\n",
            "[31:33.000 --> 31:33.900]  Will it not work?\n",
            "[31:35.100 --> 31:36.700]  And for example, there.\n"
          ]
        }
      ]
    }
  ]
}