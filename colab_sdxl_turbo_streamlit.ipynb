{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SDXL-Turbo in Colab\n",
        "\n",
        "- Make sure to connect to a GPU instance for maximum performance\n",
        "- Run all cells"
      ],
      "metadata": {
        "id": "BGE2kreuEfNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit diffusers accelerate"
      ],
      "metadata": {
        "id": "SDmitsXEwGPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8GgQJ6yznP0",
        "outputId": "9712dda3-800b-49ae-976e-d9079b7961d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.888s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgh_FVW7wCF2",
        "outputId": "5db33ce6-b156-4549-b477-5ac46449fd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "st.title(\"SDXL Turbo\")\n",
        "\n",
        "if not os.path.exists('outputs'):\n",
        "    os.makedirs('outputs')\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\", safety_checker=None).to(device)\n",
        "    # pipe.enable_freeu(s1=0.9, s2=0.2, b1=1.3, b2=1.4)\n",
        "    return pipe\n",
        "\n",
        "def realtime_gen():\n",
        "    with st.spinner('Generating image...'):\n",
        "        # Generate the image\n",
        "        image = pipe(prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "        # Display the image\n",
        "        st.image(image, caption='Generated Image')\n",
        "\n",
        "pipe = load_model()\n",
        "realtime = st.sidebar.checkbox('Realtime')\n",
        "prompt = st.sidebar.text_area(\"Enter a prompt:\", \"A cinematic shot of a baby raccoon wearing an intricate Italian priest robe.\", height=1, on_change=realtime_gen if realtime else None)\n",
        "negative_prompt = st.sidebar.text_area(\"Enter the negative prompt:\", \"low resolution, grainy, distorted\", height=1)\n",
        "num_inference_steps = st.sidebar.slider(\"Number of inference steps\", 1, 10, 1)\n",
        "guidance_scale = st.sidebar.slider(\"Guidance scale\", 0.0, 2.0, 1.0)\n",
        "\n",
        "if st.sidebar.button('Generate Image'):\n",
        "    with st.spinner('Generating image...'):\n",
        "        # Generate the image\n",
        "        image = pipe(prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "        # Generate a unique filename\n",
        "        timestamp = int(time.time())\n",
        "        random_number = random.randint(0, 99999)\n",
        "        filename = f\"outputs/image_{timestamp}_{random_number}.png\"\n",
        "\n",
        "        # Save the image\n",
        "        image.save(filename)\n",
        "\n",
        "        # Display the image\n",
        "        st.image(filename, caption='Generated Image')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random port\n",
        "!echo $((8000 + $RANDOM % 1000)) > /content/PORT.txt\n",
        "\n",
        "!echo \"Open the url, paste the below IP address in Endpoint IP field and off you go...\"\n",
        "\n",
        "# Run Streamlit app, redirect output to logs.txt, expose using localtunnel using random port, and get public IP\n",
        "!streamlit run /content/app.py --server.port $(</content/PORT.txt) &> /content/logs.txt & npx localtunnel --port $(</content/PORT.txt) & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmOkFQkJydqI",
        "outputId": "e3c192a4-e7af-4f6c-e140-0f9c0d98961b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open the url, paste the below IP address in Endpoint IP field and off you go...\n",
            "34.67.11.73\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.657s\n",
            "your url is: https://three-cycles-go.loca.lt\n"
          ]
        }
      ]
    }
  ]
}