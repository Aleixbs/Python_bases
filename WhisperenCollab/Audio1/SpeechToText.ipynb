{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJ64QmmekFbHcDFooeBv4A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aleixbs/Python_bases/blob/main/SpeechToText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "--t1G3jH5EMG",
        "outputId": "bb62c5e2-6278-4379-b698-e8e5fbd2b5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6903f2194d5c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"C:\\Users\\Usuario\\Desktop\\Audios\\audio1.mpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: OpenAI.__init__() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key)\n",
        "\n",
        "audio_file= open(r\"C:\\Users\\Usuario\\Desktop\\Audios\\audio1.mpeg\", \"rb\")\n",
        "transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=audio_file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIlH_EZN83tz",
        "outputId": "1638da22-8699-48a2-f4ae-05660d292bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-qoqwwcfo\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-qoqwwcfo\n",
            "  Resolved https://github.com/openai/whisper.git to commit 1cea4357687b676b293cb5473e1ade25f5b1cef7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=801359 sha256=cfa7c1db3d1daf2b9f52ed844c43936d625890f3a796633f86b5d9409b9a2e03\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yhf1278_/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231106 tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sguIIFwd9BKO",
        "outputId": "5ca9bb7b-9b92-474e-f5d2-59e6fbf86c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,195 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,275 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,471 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,430 kB]\n",
            "Fetched 5,604 kB in 3s (1,759 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "8 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"audio2.mp4\" --model large-v3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK8mvHsBJFkz",
        "outputId": "8b797abd-3608-4730-b448-9e5ab36572b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:23<00:00, 134MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:08.000]  ...in six municipalities and the second stage in April in another group of municipalities.\n",
            "[00:08.000 --> 00:19.000]  It's expected that in the coming months the service will be completed in the last three municipalities to complete the group of 50.\n",
            "[00:19.000 --> 00:37.000]  The number of trips has grown more. Currently, the number of trips on weekdays is on average 10,000 trips per day.\n",
            "[00:37.000 --> 00:48.000]  Which, as you see in the red slide, is an average of almost five users per bank.\n",
            "[00:48.000 --> 00:49.000]  Thank you very much.\n",
            "[00:49.000 --> 01:03.000]  Finally, in the next slide, you can see that the highest number of trips are made in the afternoon, from 5 to 8 p.m.\n",
            "[01:03.000 --> 01:12.000]  And the main stations in number of the trips are located in multiple hubs.\n",
            "[01:12.000 --> 01:18.000]  I give the word to my colleague, Jordi, who will explain the experiential vision.\n",
            "[01:18.000 --> 01:19.000]  Thank you.\n",
            "[01:19.000 --> 01:21.000]  Thank you very much.\n",
            "[01:21.000 --> 01:22.000]  Good morning, everyone.\n",
            "[01:22.000 --> 01:26.000]  I think, with the help of my colleagues, a lot of data has been provided.\n",
            "[01:26.000 --> 01:33.000]  So, I think in just five minutes or less, I would like to share the data from Viladecan.\n",
            "[01:33.000 --> 01:38.000]  Because Viladecan is a city that met with the metropolitan city.\n",
            "[01:38.000 --> 01:44.000]  That this service has been a very successful service.\n",
            "[01:44.000 --> 01:47.000]  So, I will move the slide.\n",
            "[01:47.000 --> 01:48.000]  Very successful.\n",
            "[01:48.000 --> 01:50.000]  Very fast, the data.\n",
            "[01:50.000 --> 01:54.000]  And then my experience and the experience that we have with the service.\n",
            "[01:54.000 --> 01:57.000]  This is the network of the stations in Viladecan.\n",
            "[01:57.000 --> 02:02.000]  We have 13 stations that are shorting the bike straight out by the city.\n",
            "[02:02.000 --> 02:14.000]  And so, these stations provide more than 2,200 services per day.\n",
            "[02:14.000 --> 02:17.000]  And so, this is the evolution of the users per month.\n",
            "[02:17.000 --> 02:22.000]  In April, it was very high because it was the first time that...\n",
            "[02:22.000 --> 02:29.000]  In April, it was one of the most important cities in users.\n",
            "[02:29.000 --> 02:32.000]  And then it has been decreased, as is normal.\n",
            "[02:32.000 --> 02:35.000]  But now, in the last months, it has been established.\n",
            "[02:35.000 --> 02:39.000]  So, this is a very common use, this service in the city.\n",
            "[02:39.000 --> 02:40.000]  You can...\n",
            "[02:40.000 --> 02:41.000]  Okay.\n",
            "[02:41.000 --> 02:43.000]  The monthly rate is this number.\n",
            "[02:43.000 --> 02:46.000]  It's a very large number of bikes.\n",
            "[02:46.000 --> 02:51.000]  Bikes are used by the citizens, by the neighbors.\n",
            "[02:51.000 --> 02:57.000]  And today, it's the average monthly rate of users who buy bikes.\n",
            "[02:57.000 --> 02:59.000]  And per day, it's around seven.\n",
            "[02:59.000 --> 03:03.000]  So, seven uses of bikes per day and per citizen.\n",
            "[03:03.000 --> 03:06.000]  So, it's a very interesting number.\n",
            "[03:06.000 --> 03:10.000]  The total number of users divided by the rights of bikes equals.\n",
            "[03:10.000 --> 03:14.000]  And then, my experience.\n",
            "[03:14.000 --> 03:19.000]  I would like to comment the experience of Pilates Games and the users.\n",
            "[03:19.000 --> 03:23.000]  The service is very...\n",
            "[03:23.000 --> 03:27.000]  The framework that we have in the city is to reduce emissions.\n",
            "[03:27.000 --> 03:33.000]  We are a city that we have a goal to become a neutral carbon city in 2030.\n",
            "[03:33.000 --> 03:35.000]  We are in line.\n",
            "[03:35.000 --> 03:38.000]  We will need a green capital in 2025.\n",
            "[03:38.000 --> 03:39.000]  The green leaf.\n",
            "[03:39.000 --> 03:42.000]  Because we have a lot of inhabitants.\n",
            "[03:42.000 --> 03:43.000]  The green leaf.\n",
            "[03:43.000 --> 03:46.000]  The city will be in 2025.\n",
            "[03:46.000 --> 03:50.000]  Mobility is the reference of 60% of the total emissions of CO2.\n",
            "[03:50.000 --> 03:51.000]  The ocean carbon.\n",
            "[03:51.000 --> 03:54.000]  The extra carbon.\n",
            "[03:54.000 --> 04:01.000]  So, the mobility is one of the issues that we need to reduce emissions.\n",
            "[04:01.000 --> 04:05.000]  So, this service is very interesting to reduce the emissions.\n",
            "[04:05.000 --> 04:10.000]  And the second thing that I would like to share with you is that it is possible to move from\n",
            "[04:10.000 --> 04:13.000]  the middle gangs in the metropolitan city to Barcelona.\n",
            "[04:13.000 --> 04:15.000]  This is in the north part of Barcelona.\n",
            "[04:15.000 --> 04:20.000]  This is 17 kilometers.\n",
            "[04:20.000 --> 04:28.000]  Cycling and electric bikes is around 35-40 minutes in all the paths with park lines.\n",
            "[04:28.000 --> 04:35.000]  So, it is possible to move from Barcelona to Barcelona and from Barcelona to the middle gangs.\n",
            "[04:35.000 --> 04:42.000]  Without this service, it was not possible to go cycling to Barcelona because your bike\n",
            "[04:42.000 --> 04:44.000]  maybe is not electric.\n",
            "[04:44.000 --> 04:47.000]  We decided to have electric, the main bicycles.\n",
            "[04:47.000 --> 04:56.000]  And the experience of my experience is, for instance, in San Giorgis day, in April 23,\n",
            "[04:56.000 --> 05:04.000]  when I go to Barcelona from the middle gangs with bus, by bus, to share and to spend the\n",
            "[05:04.000 --> 05:10.000]  day in the book day in San Giorgis day, to come back to Barcelona to the middle gangs,\n",
            "[05:10.000 --> 05:11.000]  I take the bicycle.\n",
            "[05:11.000 --> 05:16.000]  And I last 35 minutes from Barcelona to the middle gangs.\n",
            "[05:16.000 --> 05:19.000]  It has been the most efficient service.\n",
            "[05:19.000 --> 05:25.000]  Much more than the bus because the time spent coming to the bus on Sunday is too long.\n",
            "[05:25.000 --> 05:26.000]  And the train.\n",
            "[05:26.000 --> 05:31.000]  We got the train, we moved to the center city and spent the time.\n",
            "[05:31.000 --> 05:36.000]  And then the 15 minutes of the transit and then come back at home from the station to\n",
            "[05:36.000 --> 05:37.000]  my home.\n",
            "[05:37.000 --> 05:40.000]  So, in bus it will be approximately one hour.\n",
            "[05:40.000 --> 05:43.000]  From Barcelona to here in one Sunday.\n",
            "[05:43.000 --> 05:47.000]  By train it is one hour and one hour and a bit more.\n",
            "[05:47.000 --> 05:52.000]  And basically it was 35 minutes in Sunday.\n",
            "[05:52.000 --> 06:05.000]  And sometimes I have gone to the middle gangs in Barcelona, working in the university.\n",
            "[06:05.000 --> 06:08.000]  And if you are going to Baikara, this is a very busy city.\n",
            "[06:08.000 --> 06:12.000]  This is a very mystery and surprise what would be the traffic.\n",
            "[06:12.000 --> 06:15.000]  Traffic jams is a common thing in Barcelona.\n",
            "[06:15.000 --> 06:22.000]  If you use train, train, maybe train is not going to be working as it is needed to work.\n",
            "[06:22.000 --> 06:24.000]  So, the bicycle is always the same time.\n",
            "[06:24.000 --> 06:26.000]  40 minutes from the middle gangs to Barcelona.\n",
            "[06:26.000 --> 06:27.000]  There is no traffic jams.\n",
            "[06:27.000 --> 06:33.000]  And then you can run all the schedule on the line because the time is always the same.\n",
            "[06:33.000 --> 06:37.000]  So, in this final collection it is possible to look by the metropolitan area of Barcelona.\n",
            "[06:37.000 --> 06:46.000]  Cycling with the service is a very clean mobility and sustainable and healthy.\n",
            "[06:46.000 --> 06:51.000]  So, all the topics that are in the health-free cities and the sustainable cities you visit\n",
            "[06:51.000 --> 06:53.000]  is behind this service.\n",
            "[06:53.000 --> 06:58.000]  So, I think this service is a very, very, very future service.\n",
            "[06:58.000 --> 07:02.000]  And it is to the very end of the line of all the frameworks that the cities will have\n",
            "[07:02.000 --> 07:06.000]  to become a better network city and to reduce emissions and pollution.\n",
            "[07:06.000 --> 07:09.000]  So, I would like to thank you for the service.\n",
            "[07:09.000 --> 07:15.000]  And I think that is a good way for this type of sales inside the city.\n",
            "[07:15.000 --> 07:18.000]  Thank you very much.\n",
            "[07:25.000 --> 07:27.000]  Can we have some questions?\n",
            "[07:33.000 --> 07:35.000]  I am a head of common sense.\n",
            "[07:36.000 --> 07:51.000]  What about the infrastructure first? Of course, it takes so much time to go by line, but is it safe to sign it to Vila de Gans?\n",
            "[07:51.000 --> 08:07.240]  Now, to be from Vila de Gans to Barcelona is safe, because we have all this in the top line, only the 17 km from Vila de Becs to Barcelona, and from Barcelona to Vila de Gans.\n"
          ]
        }
      ]
    }
  ]
}